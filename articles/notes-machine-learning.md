---
title: Machine learning is fun
description: We can do something
date: 2019-06-30
---

马尔可夫假设 -> 贝叶斯网络

贝叶斯网络 vs 条件随机场

最小二乘法

在线学习

### linear-regression

* gradient descent algorithm

```
1. scale the features, for example: [-1, 1]
2. mean normalization
```

```
debugging: by plotting the cost function

if your learning rate alpha is small enough,
then J(theta) should decrease on every iteration

learning rate is too small -> slow convergence

learning rate is too large, J(theta) may not decrease
on every iteration and it may not even converge
```

```
how to choose features:

1. maybe generate new features
2. polynomial regression
```

### logistic regression (classification problems)

