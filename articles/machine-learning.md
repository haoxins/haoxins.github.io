---
title: Machine learning
description: ~
date: 2021-03-21
---

------------------

# Timeline

------------------

## 2021

* [What are the most important statistical ideas of the past 50 years?](https://arxiv.org/pdf/2012.00174.pdf)

### PyTorch

### 特征工程

* 归一化
  - 线性归一化
  - 零均值归一化 (均值为 0, 标准差为 1)

* 类别型数据
  - 序号编码
  - 独热编码
  - 二进制编码

* 文本数据
  - Word2Vec

* 组合特征
  - 提高复杂关系的拟合能力
  - 基于决策树寻找特征组合

### 模型评估

* 精确率 vs 召回率
  - P-R 曲线
  - ROC 曲线
  - F1 Score

* ROC 曲线 & AUC
* 余弦距离 vs 欧氏距离

### 经典算法

* SVM
* 逻辑回归
* 决策树
  - 特征选择
  - 树的构造
  - 树的剪枝

### 降维

* 数据集维度越高, 越稀疏, 越容易过拟合
* 投影 & 流形

* PCA 主成分分析
  - 最大化投影方差
  - 最小平方误差
* LLE 局部线性嵌入 (流形)
* LDA 线性判别分析
  - 最大化类间距离
  - 最小化类内距离

### 优化

* 凸优化
* 随机梯度下降法
  - Adam
* L1正则化
* L2正则化

* 正则化
  - 防止 过拟合
  - Dropout

* 模型集成 Dropout
* 批量归一化

### 采样

* 均匀分布随机数
  - 线性同余法

* 逆变换采样
* 拒绝采样
* 重要性采样
* 马尔可夫蒙特卡洛采样法

### 无监督学习

* 聚类
* 特征关联

* K-means
* GMM 高斯混合模型
* SOM 自组织映射

```
有监督 与 无监督 的结合

DBN (深度信念网络) 基于 无监督组件 RBM (受限玻尔兹曼机)
受限玻尔兹曼机 以无监督方式训练
然后有监督微调
```

### 集成学习

* Boosting
  - 降低偏差
* Bagging
  - (随机森林)
  - 降低方差

* 偏差 Bias
* 方差 Variance

* 最常用的基分类器 **决策树**

* GBDT 梯度提升决策树
  - 一般使用 CART 决策树

### 前向神经网络

* 神经网络训练过程的本质是学习数据分布

* 激活函数
  - 每一层线性变换后
  - 叠加一个非线性激活函数
  - 避免多层网络等效于单层线性函数

* 反向传播算法

* 深度残差网络 ResNet
  - 缓解深层神经网络的梯度消失问题

### 卷积神经网络

* 局部连接
* 权值(卷积核)共享
* 输入 -> 输出的结构保留

* 可变形卷积

* AlexNet
* VGGNet
* ResNet

* 批归一化 BN
* 全局平均池化

### 循环神经网络

* 对比传统: 隐马尔可夫模型 HMM, 条件随机场 CRF
* 对比卷积: 时间卷积网络, 因果卷积

* 难以 并行计算
* 容易 梯度消失或梯度爆炸

* LSTM 长短期记忆网络
  - 循环神经网络 最知名 & 最成功 的扩展
* GRU
* Seq2Seq

### 概率图模型

* 贝叶斯网络 有向图结构
* 马尔可夫网络 无向图网络结构

* 马尔可夫模型
* 隐马尔可夫模型

### 强化学习

* 状态转移概率已知 -> 马尔可夫决策过程
* 状态转移概率未知 -> 蒙特卡罗, 时序差分

* 基于策略迭代 vs 基于价值迭代
  - 基于价值迭代: Q-Learning, Sarsa
  - 基于策略迭代: 策略梯度

* 时序差分 -> Q-Learning
  - 只适用于处理离散状态空间
  - 不保证收敛性

* 策略梯度
  - 可以处理 离散 & 连续 状态空间
  - 保证至少收敛到一个局部最优解

* Q-Learning -> DQN

### 生成模型 & GANs

* 传统概率生成模型 vs GANs

* 可微生成网络
  - AE 自编码器
  - VAE 变分自编码器, 变分推断
  - GAN 生成式对抗网络

* GAN 的基础上引入 VAE -> ALI 对抗学习推断

### 元学习

* 适合: 小样本, 多任务, 快速学习, 快速适应
  - 需要多个不同但相关的任务支持

* LFT (Learning from Experiences): 从经验学习 (有监督学习, 强化学习)
* LTL (Learning to Learn): 学会学习
  - 训练集不同
  - 预测函数不同
  - 损失函数不同
  - 评价指标不同
  - 学习内涵不同
  - 泛化目标不同
